{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Temperature Features Exploration",
      "provenance": [],
      "authorship_tag": "ABX9TyPmVjtVylcC627AiHI5cj62",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Elzawawy/covid-case-estimator/blob/master/Temperature_Features_Exploration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obxjAbhxNfnM",
        "colab_type": "text"
      },
      "source": [
        "# Temperature Feature Exploration\n",
        "\n",
        "In this dataset we set to explore daily features for our daily cases model estimator.\n",
        "\n",
        "One of the most important daily features that could have high influence on COVID-19 cases is the temperature and its related features like humidity, wind,.etc. So, and under the lght of the previous work conclusions we explore in this notebook temperature features and expose the features in the form we need for our models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqXjgMKeNeGz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0561cc6e-6377-4136-d1e0-38cc7045f08b"
      },
      "source": [
        "#imports cell\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "from shutil import copyfile\n",
        "from enum import Enum\n",
        "\n",
        "# mount google drive to copy files from repo into drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LB9exse5NdzD",
        "colab_type": "text"
      },
      "source": [
        "### We use the Official API for https://www.kaggle.com\n",
        "\n",
        "\n",
        "*   The first dataset we explore is the Temperature Dataset by [Pierre Winter](https://www.kaggle.com/winterpierre91/covid19-global-weather-data)\n",
        "*   You can get your own Kaggle API key to run this cell by going to kaggle.com and navigating to `My Account` Tab and use the `Create API Key` button, you then upload it to the notebook's temproray storage.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUgzaJBnaP3d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "9a0dd190-5178-4802-a96d-b1b6ccf9ca7a"
      },
      "source": [
        "!pip install kaggle\n",
        "# You have to upload you own Kaggle API which is the `kaggle.json` into the temp directory first.\n",
        "!cp /content/kaggle.json ~/.kaggle/kaggle.json\n",
        "# For the Kaggle API key to be un-readable by other users on this system.\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d winterpierre91/covid19-global-weather-data\n",
        "!unzip covid19-global-weather-data.zip\n",
        "!rm covid19-global-weather-data.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.6)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Downloading covid19-global-weather-data.zip to /content\n",
            "  0% 0.00/204k [00:00<?, ?B/s]\n",
            "100% 204k/204k [00:00<00:00, 76.6MB/s]\n",
            "Archive:  covid19-global-weather-data.zip\n",
            "  inflating: temperature_dataframe.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgMhMrNG08WZ",
        "colab_type": "text"
      },
      "source": [
        "### Reading and Understanding the Global Wheather Dataset\n",
        "\n",
        "*   For each country we have useless columns and ones those we actually need. \n",
        "*   There are some countries with mutiple Provinces and thus multiple data points for each day and ones with single data row for each day (required).\n",
        "* We map those multiple provinces countries into single ones by taking the mean of features of interest across all provinces for each day.\n",
        "\n",
        "* We also drop these useless columns to us early on before processing the dataframe to save some extra time.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HPs1Jrr4zk9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "375a9906-450a-43ae-ef04-881b94cfec33"
      },
      "source": [
        "GLOBAL_WHEATHER_DATA_FILE = \"/content/temperature_dataframe.csv\"\n",
        "STORAGE_DIR = \"/content/drive/My Drive/COVID-19/daily-features/\"\n",
        "copyfile(GLOBAL_WHEATHER_DATA_FILE, STORAGE_DIR+\"global_weather_data.csv\");\n",
        "\n",
        "temperature_dataframe = pd.read_csv(STORAGE_DIR+\"global_weather_data.csv\")\n",
        "temperature_dataframe.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>province</th>\n",
              "      <th>country</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "      <th>date</th>\n",
              "      <th>cases</th>\n",
              "      <th>fatalities</th>\n",
              "      <th>capital</th>\n",
              "      <th>humidity</th>\n",
              "      <th>sunHour</th>\n",
              "      <th>tempC</th>\n",
              "      <th>windspeedKmph</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>33.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>2020-01-22</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Kabul</td>\n",
              "      <td>65.0</td>\n",
              "      <td>8.7</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>33.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>2020-01-23</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Kabul</td>\n",
              "      <td>59.0</td>\n",
              "      <td>8.7</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>33.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>2020-01-24</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Kabul</td>\n",
              "      <td>71.0</td>\n",
              "      <td>7.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>33.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>2020-01-25</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Kabul</td>\n",
              "      <td>79.0</td>\n",
              "      <td>8.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>33.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>2020-01-26</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Kabul</td>\n",
              "      <td>64.0</td>\n",
              "      <td>8.7</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  id province  ... sunHour  tempC  windspeedKmph\n",
              "0           0   1      NaN  ...     8.7   -1.0            8.0\n",
              "1           1   2      NaN  ...     8.7   -3.0            8.0\n",
              "2           2   3      NaN  ...     7.1    0.0            7.0\n",
              "3           3   4      NaN  ...     8.7    0.0            7.0\n",
              "4           4   5      NaN  ...     8.7   -1.0            8.0\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVX1m-Kh2DN6",
        "colab_type": "text"
      },
      "source": [
        "### Cleaning the dataset and preparing for Dictionary Construction\n",
        "\n",
        "1. Get country names with multiple provinces.\n",
        "2. Get country names with single provinces. \n",
        "3. Remove useless columns.\n",
        "4. Get the Dates Available Range (We know that its from 1-22 till 3-21 but need it represented in code not hard coded)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjrDXD_-2ll2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_from_dataset(dataframe):\n",
        "  # step 1: countires with NaN in province column is dropped and the rest are ones with many provinces.\n",
        "  countries_with_mutiple_provinces = dataframe.dropna(subset=[\"province\"]).country.unique()\n",
        "  # get the difference between the 2 dataframes: all countires dataframe and the countires dataframe with mutliple provinces we already built dict for above.\n",
        "  countries_with_single_province = dataframe.merge(dataframe.dropna(subset=[\"province\"]),indicator = True, how='left').loc[lambda x : x['_merge']!='both'].country.unique()\n",
        "  # step 3: remove un-needed columns from dataframe in place.\n",
        "  dataframe = dataframe.drop(columns=[\"Unnamed: 0\",\"id\",\"lat\",\"long\",\"cases\",\"fatalities\",\"capital\",\"province\"])\n",
        "  # step 4: get the avaiable date range (22-1 to 21-3) instead of hard-coding it.\n",
        "  dates_range = dataframe.date.unique()\n",
        "  return (dataframe,countries_with_mutiple_provinces,countries_with_single_province,dates_range)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSZlQfVb3sSW",
        "colab_type": "text"
      },
      "source": [
        "### Create Feature Dictionary Method\n",
        "\n",
        "1. Calls the `extract_from_dataset` method to prepare dataframe and extract needed smaller Pandas Dataframes Objects.\n",
        "\n",
        "2. Creates `K:Country- V:Feature` Dictionary for the feature asked for in the params for those countries with multiple provinces first as they need special handling and needs to calculate the mean for their provinces first.\n",
        "\n",
        "3. Creates `K:Country- V:Feature` Dictionary for the feature asked for in the params for these rest of counties with only one single province which is easier to handle.\n",
        "\n",
        "**Notes about data that had to be handled:**\n",
        "\n",
        "* There were found some countires with no desired features, that's why we add the count != 0 check at the second loop. \n",
        "\n",
        "* There were found one country (Gambia) with duplicated data for each day, that's why we add the drop_duplicates() at the second loop as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9FG12-nUGL1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_feature_dict(dataframe, feature):\n",
        "  if(feature not in ['tempC', 'humidity','sunHour', 'windspeedKmph']):\n",
        "    raise Exception(\"Feature must be one of the four temperature-related features\")\n",
        "  (dataframe,multi_countries,single_countries,avail_dates) = extract_from_dataset(dataframe)\n",
        "  # iterate on each country and create a dictionary for feature where the key is the country and the value.\n",
        "  country_dict = {}\n",
        "  country_feature = []\n",
        "  for country in multi_countries:\n",
        "    # iterate on each date available for this country provinces and get a mean value for them.\n",
        "    for date in avail_dates:\n",
        "      country_feature.append(dataframe[(dataframe['country'] == country) & (dataframe['date'] == date)].mean()[feature])\n",
        "    country_dict[country] = np.array(country_feature)\n",
        "    country_feature.clear()\n",
        "\n",
        "  # iterate on each country and create a dictionary for feature where the key is the country and the value.\n",
        "  for country in single_countries:\n",
        "      # Gambia Data has an issue because all of its dates are repeated two times, so we have to drop duplicates.\n",
        "      feature_series = dataframe[dataframe['country'] == country].drop_duplicates()[feature]\n",
        "      # escape counties with no feature data.\n",
        "      if(feature_series.count() != 0):\n",
        "        country_dict[country] = feature_series.to_numpy()\n",
        "  return country_dict\n",
        "\n",
        "def save_dict_to_csv(dict, csv_file):\n",
        "  w = csv.writer(open(csv_file, \"w\"))\n",
        "  for key, val in dict.items():\n",
        "      w.writerow([key, val])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqohiVrF-7mI",
        "colab_type": "text"
      },
      "source": [
        "### Finally, we iterate on each feature from our four temperature-related features.\n",
        "\n",
        "* Obtain a country and feature dictionary, where the key is the string country name and the value is 1-darray of values ranging from Day 1 till Day 60. (i.e 1-D array with 60 values)\n",
        "\n",
        "* Save that dictionary into a csv file in permanent google drive storage for later use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELsDqt2uFKAC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for feature in ['tempC', 'humidity','sunHour', 'windspeedKmph']:\n",
        "  country_feature_dict = create_feature_dict(temperature_dataframe, feature)\n",
        "  save_dict_to_csv(country_feature_dict, STORAGE_DIR+feature+\"_dict.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}