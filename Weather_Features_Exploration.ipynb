{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Weather Features Exploration",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMM8Xn1vrDX2GWGfEeAOqCM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Elzawawy/covid-case-estimator/blob/master/Weather_Features_Exploration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obxjAbhxNfnM",
        "colab_type": "text"
      },
      "source": [
        "# Weather Features Exploration\n",
        "\n",
        "In this dataset we set to explore weather features for our daily cases model estimator.\n",
        "\n",
        "One of the most important daily features that could have high influence on COVID-19 cases is the weather and its related features like temperature, humidity, wind,.etc. So, and under the light of the previous work conclusions we wish to analyze the weather and temperature data of the respective countries since the outbreak of the virus.|"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqXjgMKeNeGz",
        "colab_type": "code",
        "outputId": "84889083-1c7b-4a18-f439-92aed0944981",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#imports cell\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from shutil import copyfile\n",
        "\n",
        "# mount google drive to copy files from repo into drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LB9exse5NdzD",
        "colab_type": "text"
      },
      "source": [
        "### We use the Official API for https://www.kaggle.com to get our datasets.\n",
        "\n",
        "*   You can get your own Kaggle API key to run this cell by going to kaggle.com and navigating to `My Account` Tab and use the `Create API Key` button, you then upload it to the notebook's temproray storage.\n",
        "\n",
        "*   The first dataset we explore is the Global Weather Dataset for COVID-19 by [Pierre Winter](https://www.kaggle.com/winterpierre91/covid19-global-weather-data)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUgzaJBnaP3d",
        "colab_type": "code",
        "outputId": "294af5b3-32a7-4f94-beb2-275e1adfe328",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "!pip install kaggle\n",
        "# You have to upload you own Kaggle API which is the `kaggle.json` into the temp directory first.\n",
        "!cp /content/kaggle.json ~/.kaggle/kaggle.json\n",
        "# For the Kaggle API key to be un-readable by other users on this system.\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d winterpierre91/covid19-global-weather-data\n",
        "!unzip covid19-global-weather-data.zip\n",
        "!rm covid19-global-weather-data.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.6)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2020.4.5.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.41.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.9)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Downloading covid19-global-weather-data.zip to /content\n",
            "  0% 0.00/204k [00:00<?, ?B/s]\n",
            "100% 204k/204k [00:00<00:00, 55.3MB/s]\n",
            "Archive:  covid19-global-weather-data.zip\n",
            "  inflating: temperature_dataframe.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgMhMrNG08WZ",
        "colab_type": "text"
      },
      "source": [
        "### Reading and Understanding the Global Wheather Dataset\n",
        "\n",
        "*   For each country we have useless columns and ones those we actually need. \n",
        "*   There are some countries with mutiple Provinces and thus multiple data points for each day and ones with single data row for each day (required).\n",
        "* We map those multiple provinces countries into single ones by taking the mean of features of interest across all provinces for each day.\n",
        "\n",
        "* We also drop these useless columns to us early on before processing the dataframe to save some extra time.\n",
        "\n",
        "### Weather Features\n",
        "\n",
        "We hope to find some colleration between certain weather metrics and the speed of the number of infections/deaths.\n",
        "\n",
        "1. **Temperature ('tempC'):** Temperature measured daily in degrees Celsius.\n",
        "\n",
        "2. **Humidity ('humidity'):** Humidity measured daily, which is the amount of water vapour in the atmosphere or in a gas.\n",
        "\n",
        "3. **Hours of SunLight ('sunHour'):** Although the daytime length at the Equator remains 12 hours in all seasons, the duration at all other latitudes varies with the seasons. During the winter, daytime lasts shorter than 12 hours; during the summer, it lasts longer than 12 hours.\n",
        "\n",
        "4. **Wind Speed ('windspeedKmph'):** It is a fundamental atmospheric quantity caused by air moving from high to low pressure, usually due to changes in temperature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HPs1Jrr4zk9",
        "colab_type": "code",
        "outputId": "83296c2f-c5bd-4f07-8f7c-32979e2fd988",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "GLOBAL_WHEATHER_DATA_FILE = \"/content/temperature_dataframe.csv\"\n",
        "STORAGE_DIR = \"/content/drive/My Drive/COVID-19/weather-features/\"\n",
        "copyfile(GLOBAL_WHEATHER_DATA_FILE, STORAGE_DIR+\"global_weather_data.csv\");\n",
        "\n",
        "temperature_dataframe = pd.read_csv(STORAGE_DIR+\"global_weather_data.csv\")\n",
        "temperature_dataframe.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>province</th>\n",
              "      <th>country</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "      <th>date</th>\n",
              "      <th>cases</th>\n",
              "      <th>fatalities</th>\n",
              "      <th>capital</th>\n",
              "      <th>humidity</th>\n",
              "      <th>sunHour</th>\n",
              "      <th>tempC</th>\n",
              "      <th>windspeedKmph</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>33.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>2020-01-22</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Kabul</td>\n",
              "      <td>65.0</td>\n",
              "      <td>8.7</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>33.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>2020-01-23</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Kabul</td>\n",
              "      <td>59.0</td>\n",
              "      <td>8.7</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>33.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>2020-01-24</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Kabul</td>\n",
              "      <td>71.0</td>\n",
              "      <td>7.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>33.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>2020-01-25</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Kabul</td>\n",
              "      <td>79.0</td>\n",
              "      <td>8.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>33.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>2020-01-26</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Kabul</td>\n",
              "      <td>64.0</td>\n",
              "      <td>8.7</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  id province  ... sunHour  tempC  windspeedKmph\n",
              "0           0   1      NaN  ...     8.7   -1.0            8.0\n",
              "1           1   2      NaN  ...     8.7   -3.0            8.0\n",
              "2           2   3      NaN  ...     7.1    0.0            7.0\n",
              "3           3   4      NaN  ...     8.7    0.0            7.0\n",
              "4           4   5      NaN  ...     8.7   -1.0            8.0\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVX1m-Kh2DN6",
        "colab_type": "text"
      },
      "source": [
        "### Cleaning the dataset and preparing for Dictionary Construction\n",
        "\n",
        "1. Get country names with multiple provinces.\n",
        "2. Get country names with single provinces. \n",
        "3. Remove useless columns.\n",
        "4. Get the Dates Available Range (We know that its from 1-22 till 3-21 but need it represented in code not hard coded)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjrDXD_-2ll2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_from_dataset(dataframe):\n",
        "  # step 1: countires with NaN in province column is dropped and the rest are ones with many provinces.\n",
        "  countries_with_mutiple_provinces = dataframe.dropna(subset=[\"province\"]).country.unique()\n",
        "  # get the difference between the 2 dataframes: all countires dataframe and the countires dataframe with mutliple provinces we already built dict for above.\n",
        "  countries_with_single_province = dataframe.merge(dataframe.dropna(subset=[\"province\"]),indicator = True, how='left').loc[lambda x : x['_merge']!='both'].country.unique()\n",
        "  # step 3: remove un-needed columns from dataframe in place.\n",
        "  dataframe = dataframe.drop(columns=[\"Unnamed: 0\",\"id\",\"lat\",\"long\",\"cases\",\"fatalities\",\"capital\",\"province\"])\n",
        "  # step 4: get the avaiable date range (22-1 to 21-3) instead of hard-coding it.\n",
        "  dates_range = dataframe.date.unique()\n",
        "  return (dataframe,countries_with_mutiple_provinces,countries_with_single_province,dates_range)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSZlQfVb3sSW",
        "colab_type": "text"
      },
      "source": [
        "### Create Feature Dictionary Method\n",
        "\n",
        "1. Calls the `extract_from_dataset` method to prepare dataframe and extract needed smaller Pandas Dataframes Objects.\n",
        "\n",
        "2. Creates `K:Country- V:Feature` Dictionary for the feature asked for in the params for those countries with multiple provinces first as they need special handling and needs to calculate the mean for their provinces first.\n",
        "\n",
        "3. Creates `K:Country- V:Feature` Dictionary for the feature asked for in the params for these rest of counties with only one single province which is easier to handle.\n",
        "\n",
        "**Notes about data that had to be handled:**\n",
        "\n",
        "* There were found some countires with no desired features, that's why we add the count != 0 check at the second loop. \n",
        "\n",
        "* There were found one country (Gambia) with duplicated data for each day, that's why we add the drop_duplicates() at the second loop as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9FG12-nUGL1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_feature_dict(dataframe, feature):\n",
        "  if(feature not in ['tempC', 'humidity','sunHour', 'windspeedKmph']):\n",
        "    raise Exception(\"Feature must be one of the four temperature-related features\")\n",
        "  (dataframe,multi_countries,single_countries,avail_dates) = extract_from_dataset(dataframe)\n",
        "  # iterate on each country and create a dictionary for feature where the key is the country and the value.\n",
        "  country_dict = {}\n",
        "  country_feature = []\n",
        "  for country in multi_countries:\n",
        "    # iterate on each date available for this country provinces and get a mean value for them.\n",
        "    for date in avail_dates:\n",
        "      country_feature.append(dataframe[(dataframe['country'] == country) & (dataframe['date'] == date)].mean()[feature])\n",
        "    country_dict[country] = np.array(country_feature)\n",
        "    country_feature.clear()\n",
        "\n",
        "  # iterate on each country and create a dictionary for feature where the key is the country and the value.\n",
        "  for country in single_countries:\n",
        "      # Gambia Data has an issue because all of its dates are repeated two times, so we have to drop duplicates.\n",
        "      feature_series = dataframe[dataframe['country'] == country].drop_duplicates()[feature]\n",
        "      # escape counties with no feature data.\n",
        "      if(feature_series.count() != 0):\n",
        "        country_dict[country] = feature_series.to_numpy()\n",
        "  return country_dict\n",
        "\n",
        "def save_dict_to_pickle(dict, pickle_file):\n",
        "  with open(pickle_file, 'wb') as handle:\n",
        "    pickle.dump(dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqohiVrF-7mI",
        "colab_type": "text"
      },
      "source": [
        "### Finally, we iterate on each feature from our four weather features.\n",
        "\n",
        "* Obtain a country and feature dictionary, where the key is the string country name and the value is 1-darray of values ranging from Day 1 till Day 60. (i.e 1-D array with 60 values)\n",
        "\n",
        "* Save that dictionary into a csv file in permanent google drive storage for later use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELsDqt2uFKAC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for feature in ['tempC', 'humidity','sunHour', 'windspeedKmph']:\n",
        "  country_feature_dict = create_feature_dict(temperature_dataframe, feature)\n",
        "  save_dict_to_pickle(country_feature_dict, STORAGE_DIR+feature+\"_dict.pickle\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}